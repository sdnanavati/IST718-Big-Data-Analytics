# -*- coding: utf-8 -*-
"""IST_718_Life_Expectancy.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ttbv3bThFGCpBfa1JecHVRebpu4FSYRo
"""

from google.colab import drive
drive.mount('/content/drive/')

#Import libraries and packages

import pandas as pd #to create dataframe and read csv files
import numpy as np #contains computations and functions
import matplotlib.pyplot as plt #to create plots and graphs
import seaborn as sns #to create graphs
from sklearn.model_selection import train_test_split #split data into train and test sets
from sklearn.linear_model import LinearRegression #linear regression model
from sklearn.metrics import r2_score #to calculate r-squared of model

# Read in life expectancy &  % GDP Healthcare data sets into a data frame and merge the two

# Load the data from the CSV files into pandas DataFrames
df1 = pd.read_csv("https://raw.githubusercontent.com/wood0639/IST_718_Life_Expectancy_Project/main/gdp_healthcare.csv", skiprows=3)
df2 = pd.read_csv("https://raw.githubusercontent.com/wood0639/IST_718_Life_Expectancy_Project/main/Life%20Expectancy%20Data.csv") 

# Drop unneccessary cols
df2 = df2.drop(columns = ['Alcohol', 'percentage expenditure', 'Hepatitis B', 'Measles ','Polio', 'Total expenditure', 'Diphtheria ', ' HIV/AIDS', ' thinness  1-19 years', ' thinness 5-9 years'])# 'Hepatitis B', 'Measles', 'Polio', 'Total expenditure', 'Diphtheria', 'HIV/AIDS', 'thinness 1-19 years', 'thinness 5-9 years'], axis = 1)

# Select the "Country Name" column
country_name = df1.iloc[:, 0]

# Select the columns from "2000" to "2015"
years = df1.loc[:, "2000":"2015"]

# Concatenate the two DataFrames along the columns axis
df1 = pd.concat([country_name, years], axis=1)

# Transpose
df1 = df1.melt(id_vars=["Country Name"], var_name="Year", value_name="GDP_Healthcare")

# Rename column
df1.rename(columns={"Country Name": "Country"}, inplace=True)

# Change Year to int
df1['Year'] = df1['Year'].astype(int)

# Merge df1 & df2
df = pd.merge(df1,df2, on = ["Country", "Year"])

df.head()



# Read in communicable diseases data set into a data frame

comm_dis = pd.read_csv('drive/Shareddrives/IST_718_Final_Project/communicable diseases.csv', skiprows=6, index_col=False, usecols = ['Region Code', 'Region Name', 'Country Code', 'Country Name', 'Year', 'Sex', 'Age Group', 'Number'])
comm_dis

#Re-name column in comm_dis data set
comm_dis.rename(columns={'Country Name':'Country'}, inplace=True)

# Rename Number column
comm_dis.rename(columns = {'Number' : 'comm_dis'}, inplace = True)
comm_dis

# Read in noncommunicable diseases data set into a data frame

non_comm = pd.read_csv('drive/Shareddrives/IST_718_Final_Project/noncommunicable diseases.csv', skiprows=6, index_col=False, usecols = ['Region Code', 'Region Name', 'Country Code', 'Country Name', 'Year', 'Sex', 'Age Group', 'Number'])
non_comm

#Re-name column in non_comm data set
non_comm.rename(columns={'Country Name':'Country'}, inplace=True)

# Rename Number column
non_comm.rename(columns = {'Number' : 'non_comm'}, inplace = True)
non_comm

# Read in ill-defined diseases data set into a data frame

ill = pd.read_csv("drive/Shareddrives/IST_718_Final_Project/ill-defined diseases.csv", skiprows=6, index_col=False, usecols = ['Region Code', 'Region Name', 'Country Code', 'Country Name', 'Year', 'Sex', 'Age Group', 'Number'])
ill

#Re-name column in ill data set
ill.rename(columns={'Country Name':'Country'}, inplace=True)

# Rename Number column
ill.rename(columns = {'Number' : 'ill'}, inplace = True)
ill

# Merge ill and non_comm data sets
ill_non= pd.merge(ill, non_comm, on=['Country','Year', 'Sex', 'Age Group', 'Country Code', 'Region Name', 'Region Code'])
ill_non.info()

# Read in injuries data set into a data frame

inj = pd.read_csv("drive/Shareddrives/IST_718_Final_Project/injuries.csv", skiprows=6, index_col=False, usecols = ['Region Code', 'Region Name', 'Country Code', 'Country Name', 'Year', 'Sex', 'Age Group', 'Number'])
inj.head()

#Re-name column in inj data set
inj.rename(columns={'Country Name':'Country'}, inplace=True)

# Rename Number column
inj.rename(columns = {'Number' : 'inj'}, inplace = True)
inj.head()

# Merge inj and comm_dis data sets
inj_comm= pd.merge(inj, comm_dis, on=['Country','Year', 'Region Code', 'Region Name', 'Country Code', 'Sex', 'Age Group'])
inj_comm.head()

inj_comm.info()

# Merge inj_comm and ill_non data sets
mort_comb = pd.merge(inj_comm, ill_non, on = ['Country','Year', 'Region Code', 'Region Name', 'Country Code', 'Sex', 'Age Group'])
mort_comb.head()

mort_comb.info()

df.info()

# Merge df and mort_comb data sets
df_comb = pd.merge(df, mort_comb, on = ["Country", "Year"])
df_comb

# Show general info of data set
df_comb.info()

# Remove white space from all column titles in pandas dataframe
df_comb.columns = df_comb.columns.str.strip() 

# Lowercase all column titles in pandas dataframe
df_comb.columns = [x.lower() for x in df_comb.columns]

# Remove NA values
df_comb = df_comb.dropna()


df_comb.head()

df_comb.info()

# To find the correlation among the variables in data set
# the columns using pearson method
pcorr_df_comb = df_comb.corr(method ='pearson')
pcorr_df_comb

# Utilize heatmap to better identify stronger relationships
plt.figure(figsize=(16, 6))
sns.heatmap(pcorr_df_comb, vmin=-1, vmax=1, annot=True)

# Plot life expectancy vs adult mortality 
mortality = df_comb.plot.scatter(x='adult mortality', y='life expectancy', c='life expectancy', 
                               figsize=(8,4),cmap='viridis',title='Life Expectancy based on Adult Mortality', sharex=False)
mortality

# Plot life expectancy vs infant deaths
infant = df_comb.plot.scatter(x='infant deaths', y='life expectancy', c='life expectancy', 
                               figsize=(8,4),cmap='viridis',title='Life Expectancy based on Infant Deaths', sharex=False)
infant

df_comb

# Create new df for life expectancy
df_life_exp =pd.DataFrame(df_comb.groupby(['country'])['life expectancy'].mean())

# Find smallest life expectancy from df above
small_life = df_life_exp.nsmallest(10, 'life expectancy')

# Find longest life expectancy from df above
long_life = df_life_exp.nlargest(10, 'life expectancy')

# Sort longest life expectancy to ascending 
long_life = long_life.sort_values('life expectancy',ascending = True)
long_life

# Create bar plot for smallest life expectancy
ax = small_life.plot(kind = 'barh', ylim = (0,90))

#annotate bars
ax.bar_label(ax.containers[0])

# Create bar plot for longest life expectancy
ax = long_life.plot(kind = 'barh', ylim = (0,90))

#annotate bars
ax.bar_label(ax.containers[0])

# Filter the data by country names
countries = ['South Africa', 'Turkmenistan', 'Tajikistan', 'Guyana', 'Kazakhstan', 
             'Philippines', 'Russian Federation', 'Uzbekistan', 'Fiji', 'Azerbaijan']
small_data = df_comb[df_comb['country'].isin(countries)].groupby('country')

# Calculate the means of the variables for each country
small_cause = small_data[['inj', 'comm_dis', 'ill', 'non_comm']].mean()

# Calculate the totals of the variables for each country
totals_mean = small_cause[['inj', 'comm_dis', 'ill', 'non_comm']].mean()
totals_sum = small_cause[['inj', 'comm_dis', 'ill', 'non_comm']].sum()
small_cause

# Create bar plot for smallest life expectancy cause of death
ax = small_cause.plot(kind = 'barh', ylim = (0,90))

#annotate bars
ax.bar_label(ax.containers[0])

# Totals of cause of death categories for the 10 countries with smallest life expectancy
print(totals_sum)

print(totals_mean)

# Filter the long life data by country names
countries2 = ['Canada', 'Norway', 'Australia', 'Spain', 'Italy', 'France', 'Switzerland', 'Iceland', 'Sweden', 'Japan']
long_data = df_comb[df_comb['country'].isin(countries2)].groupby('country')

# Calculate the means of the variables for each country
long_cause = long_data[['gdp_healthcare']].mean()

# Sort longest life expectancy to ascending 
long_cause = long_cause.sort_values('gdp_healthcare',ascending = True)

# Calculate the mean of the variable for each country
totals2 = long_cause[['gdp_healthcare']].mean()
long_cause

# Top GDP Healthcare spenders
# Filter the long life data by country names
long_datanew = df_comb.groupby('country')

# Calculate the means of the variables for each country
long_causenew = long_datanew[['gdp_healthcare']].mean()

# Sort longest life expectancy to ascending 
long_causenew = long_causenew.sort_values('gdp_healthcare',ascending = True)

# Calculate the mean of the variable for each country
totalsnew = long_causenew[['gdp_healthcare']].mean()

long_causenew = long_causenew.reset_index()
long_causenew['Top Check'] = long_causenew['country'].apply(lambda x: 1 if x in countries2 else 0)
long_causenew[-25:]

# Average % of GDP spent on healthcare for longest lived 10 countries
print(totals2)

# Create bar plot for longest life expectancy % gdp used on healthcare
ax = long_cause.plot(kind = 'barh')

#annotate bars
ax.bar_label(ax.containers[0])

# filter by status
developing = df_comb[df_comb['status'] == 'Developing']
developed = df_comb[df_comb['status'] == 'Developed']

# calculate average life expectancy by year for each status
dev_avg_life = developing.groupby('year')['life expectancy'].mean()
devd_avg_life = developed.groupby('year')['life expectancy'].mean()

# create line chart
fig, ax = plt.subplots(figsize=(10, 5), dpi=150)
ax.plot(dev_avg_life.index, dev_avg_life.values, label='Developing')
ax.plot(devd_avg_life.index, devd_avg_life.values, label='Developed')
ax.set_xlabel('Year')
ax.set_ylabel('Average Life Expectancy')
ax.set_xticks(range(2000, 2016))
ax.legend()

# add title and save figure
plt.title('Average Life Expectancy by Year and Status')
#plt.savefig('life_expectancy.png')
plt.show()

# set the width of the bars
width = 0.35

# create grouped bar chart
fig, ax = plt.subplots(figsize=(10, 5))
ind = np.arange(len(dev_avg_life.index))
ax.bar(ind, dev_avg_life.values, width, label='Developing')
ax.bar(ind + width, devd_avg_life.values, width, label='Developed')

# add totals above each bar
for i, v in enumerate(dev_avg_life.values):
    ax.text(i - 0.15, v + 1, str(round(v, 2)), fontsize=10, color='blue')
for i, v in enumerate(devd_avg_life.values):
    ax.text(i + width - 0.15, v + 1, str(round(v, 2)), fontsize=10, color='orange')

# add labels, legend, and title
ax.set_xlabel('Year')
ax.set_ylabel('Average Life Expectancy')
ax.legend()
plt.title('Average Life Expectancy by Year and Status')

# adjust figure size and label positioning
fig.tight_layout()
ax.set_xticks(ind + width / 2)
ax.set_xticklabels(dev_avg_life.index)

plt.show()

# filter top and bottom 10 countries by life expectancy
top_10 = df_comb.groupby('country')['life expectancy'].mean().nlargest(10).index
bottom_10 = df_comb.groupby('country')['life expectancy'].mean().nsmallest(10).index
df_top_10 = df_comb[df_comb['country'].isin(top_10)]
df_bottom_10 = df_comb[df_comb['country'].isin(bottom_10)]

# calculate average life expectancy by year for top and bottom 10 countries
top_10_avg_life = df_top_10.groupby('year')['life expectancy'].mean()
bottom_10_avg_life = df_bottom_10.groupby('year')['life expectancy'].mean()

# create line chart
fig, ax = plt.subplots(figsize=(10, 5), dpi=150)
ax.plot(top_10_avg_life.index, top_10_avg_life.values, label='Top 10 Countries')
ax.plot(bottom_10_avg_life.index, bottom_10_avg_life.values, label='Bottom 10 Countries')
ax.set_xlabel('Year')
ax.set_ylabel('Average Life Expectancy')
ax.set_xticks(range(2000, 2016))
ax.set_ylim(60, 90)  # set ylim to (60, 90)
ax.legend()

# add title and save figure
plt.title('Average Life Expectancy by Year for Top and Bottom 10 Countries')
#plt.savefig('life_expectancy_top_bottom.png')
plt.show()

#df_combln2.plot.scatter(x='gdp',y='life expectancy',c='region code',cmap='viridis',s= 'status',legend=True, marker = 'd')

"""#Time Series Forecast"""

developing





# Read in all Non-communicable disease files to narrow down scope

######################
# Read in cardio_dis df
cardio_dis = pd.read_csv('drive/Shareddrives/IST_718_Final_Project/cardiovascular diseases.csv', skiprows=6, index_col=False, usecols = ['Region Code', 'Region Name', 'Country Code', 'Country Name', 'Year', 'Sex', 'Age Group', 'Number'])

# Re-name column in cardio_dis data set
cardio_dis.rename(columns={'Country Name':'Country'}, inplace=True)

# Rename Number column
cardio_dis.rename(columns = {'Number' : 'cardio_dis'}, inplace = True)
######################
# Read in cong_anom df
cong_anom = pd.read_csv('drive/Shareddrives/IST_718_Final_Project/congenital anomalies.csv', skiprows=6, index_col=False, usecols = ['Region Code', 'Region Name', 'Country Code', 'Country Name', 'Year', 'Sex', 'Age Group', 'Number'])

# Re-name column in cong_anom data set
cong_anom.rename(columns={'Country Name':'Country'}, inplace=True)

# Rename Number column
cong_anom.rename(columns = {'Number' : 'cong_anom'}, inplace = True)
######################
# Read in dia_end df
dia_end = pd.read_csv('drive/Shareddrives/IST_718_Final_Project/diabetes & endocrine.csv', skiprows=6, index_col=False, usecols = ['Region Code', 'Region Name', 'Country Code', 'Country Name', 'Year', 'Sex', 'Age Group', 'Number'])

# Re-name column in dia_end data set
dia_end.rename(columns={'Country Name':'Country'}, inplace=True)

# Rename Number column
dia_end.rename(columns = {'Number' : 'dia_end'}, inplace = True)
######################
# Read in dig_dis df
dig_dis = pd.read_csv('drive/Shareddrives/IST_718_Final_Project/digestive diseases.csv', skiprows=6, index_col=False, usecols = ['Region Code', 'Region Name', 'Country Code', 'Country Name', 'Year', 'Sex', 'Age Group', 'Number'])

# Re-name column in dig_dis data set
dig_dis.rename(columns={'Country Name':'Country'}, inplace=True)

# Rename Number column
dig_dis.rename(columns = {'Number' : 'dig_dis'}, inplace = True)
######################
# Read in genit_dis df
genit_dis = pd.read_csv('drive/Shareddrives/IST_718_Final_Project/genitourinary diseases.csv', skiprows=6, index_col=False, usecols = ['Region Code', 'Region Name', 'Country Code', 'Country Name', 'Year', 'Sex', 'Age Group', 'Number'])

# Re-name column in genit_dis data set
genit_dis.rename(columns={'Country Name':'Country'}, inplace=True)

# Rename Number column
genit_dis.rename(columns = {'Number' : 'genit_dis'}, inplace = True)
######################
# Read in mal_neo df
mal_neo = pd.read_csv('drive/Shareddrives/IST_718_Final_Project/malignant neoplasms.csv', skiprows=6, index_col=False, usecols = ['Region Code', 'Region Name', 'Country Code', 'Country Name', 'Year', 'Sex', 'Age Group', 'Number'])

# Re-name column in mal_neo data set
mal_neo.rename(columns={'Country Name':'Country'}, inplace=True)

# Rename Number column
mal_neo.rename(columns = {'Number' : 'mal_neo'}, inplace = True)
######################
# Read in mus_skel_dis df
mus_skel_dis = pd.read_csv('drive/Shareddrives/IST_718_Final_Project/musculoskeletal diseases.csv', skiprows=6, index_col=False, usecols = ['Region Code', 'Region Name', 'Country Code', 'Country Name', 'Year', 'Sex', 'Age Group', 'Number'])

# Re-name column in mus_skel_dis data set
mus_skel_dis.rename(columns={'Country Name':'Country'}, inplace=True)

# Rename Number column
mus_skel_dis.rename(columns = {'Number' : 'mus_skel_dis'}, inplace = True)
######################
# Read in neur_psy df
neur_psy = pd.read_csv('drive/Shareddrives/IST_718_Final_Project/neuropsychiatric conditions.csv', skiprows=6, index_col=False, usecols = ['Region Code', 'Region Name', 'Country Code', 'Country Name', 'Year', 'Sex', 'Age Group', 'Number'])

# Re-name column in neur_psy data set
neur_psy.rename(columns={'Country Name':'Country'}, inplace=True)

# Rename Number column
neur_psy.rename(columns = {'Number' : 'neur_psy'}, inplace = True)
######################
# Read in oral_con df
oral_con = pd.read_csv('drive/Shareddrives/IST_718_Final_Project/oral conditions.csv', skiprows=6, index_col=False, usecols = ['Region Code', 'Region Name', 'Country Code', 'Country Name', 'Year', 'Sex', 'Age Group', 'Number'])

# Re-name column in oral_con data set
oral_con.rename(columns={'Country Name':'Country'}, inplace=True)

# Rename Number column
oral_con.rename(columns = {'Number' : 'oral_con'}, inplace = True)
######################
# Read in oth_neo df
oth_neo = pd.read_csv('drive/Shareddrives/IST_718_Final_Project/other neoplasms.csv', skiprows=6, index_col=False, usecols = ['Region Code', 'Region Name', 'Country Code', 'Country Name', 'Year', 'Sex', 'Age Group', 'Number'])

# Re-name column in cong_anom data set
oth_neo.rename(columns={'Country Name':'Country'}, inplace=True)

# Rename Number column
oth_neo.rename(columns = {'Number' : 'oth_neo'}, inplace = True)
######################
# Read in resp_dis df
resp_dis = pd.read_csv('drive/Shareddrives/IST_718_Final_Project/respiratory diseases.csv', skiprows=6, index_col=False, usecols = ['Region Code', 'Region Name', 'Country Code', 'Country Name', 'Year', 'Sex', 'Age Group', 'Number'])

# Re-name column in resp_dis data set
resp_dis.rename(columns={'Country Name':'Country'}, inplace=True)

# Rename Number column
resp_dis.rename(columns = {'Number' : 'resp_dis'}, inplace = True)
######################
# Read in sen_org_dis df
sen_org_dis = pd.read_csv('drive/Shareddrives/IST_718_Final_Project/sense organ diseases.csv', skiprows=6, index_col=False, usecols = ['Region Code', 'Region Name', 'Country Code', 'Country Name', 'Year', 'Sex', 'Age Group', 'Number'])

# Re-name column in sen_org_dis data set
sen_org_dis.rename(columns={'Country Name':'Country'}, inplace=True)

# Rename Number column
sen_org_dis.rename(columns = {'Number' : 'sen_org_dis'}, inplace = True)
######################
# Read in skin_dis df
skin_dis = pd.read_csv('drive/Shareddrives/IST_718_Final_Project/skin diseases.csv', skiprows=6, index_col=False, usecols = ['Region Code', 'Region Name', 'Country Code', 'Country Name', 'Year', 'Sex', 'Age Group', 'Number'])

# Re-name column in skin_dis data set
skin_dis.rename(columns={'Country Name':'Country'}, inplace=True)

# Rename Number column
skin_dis.rename(columns = {'Number' : 'skin_dis'}, inplace = True)
######################
# Read in sids df
sids = pd.read_csv('drive/Shareddrives/IST_718_Final_Project/congenital anomalies.csv', skiprows=6, index_col=False, usecols = ['Region Code', 'Region Name', 'Country Code', 'Country Name', 'Year', 'Sex', 'Age Group', 'Number'])

# Re-name column in sids data set
sids.rename(columns={'Country Name':'Country'}, inplace=True)

# Rename Number column
sids.rename(columns = {'Number' : 'sids'}, inplace = True)
######################

# Merge all non-communicable disease data sets
non_comm_comb = pd.merge(cardio_dis,
                         cong_anom,
                         on=['Country','Year', 'Region Code', 'Region Name', 'Country Code', 'Sex', 'Age Group'],
                         how='inner')
non_comm_comb = pd.merge(non_comm_comb,
                         dia_end,
                         on=['Country','Year', 'Region Code', 'Region Name', 'Country Code', 'Sex', 'Age Group'],
                         how='inner')
non_comm_comb = pd.merge(non_comm_comb,
                         dig_dis,
                         on=['Country','Year', 'Region Code', 'Region Name', 'Country Code', 'Sex', 'Age Group'],
                         how='inner')
non_comm_comb = pd.merge(non_comm_comb,
                         genit_dis,
                         on=['Country','Year', 'Region Code', 'Region Name', 'Country Code', 'Sex', 'Age Group'],
                         how='inner')
non_comm_comb = pd.merge(non_comm_comb,
                         mal_neo,
                         on=['Country','Year', 'Region Code', 'Region Name', 'Country Code', 'Sex', 'Age Group'],
                         how='inner')
non_comm_comb = pd.merge(non_comm_comb,
                         mus_skel_dis,
                         on=['Country','Year', 'Region Code', 'Region Name', 'Country Code', 'Sex', 'Age Group'],
                         how='inner')
non_comm_comb = pd.merge(non_comm_comb,
                         neur_psy,
                         on=['Country','Year', 'Region Code', 'Region Name', 'Country Code', 'Sex', 'Age Group'],
                         how='inner')
non_comm_comb = pd.merge(non_comm_comb,
                         oral_con,
                         on=['Country','Year', 'Region Code', 'Region Name', 'Country Code', 'Sex', 'Age Group'],
                         how='inner')
non_comm_comb = pd.merge(non_comm_comb,
                         oth_neo,
                         on=['Country','Year', 'Region Code', 'Region Name', 'Country Code', 'Sex', 'Age Group'],
                         how='inner')
non_comm_comb = pd.merge(non_comm_comb,
                         resp_dis,
                         on=['Country','Year', 'Region Code', 'Region Name', 'Country Code', 'Sex', 'Age Group'],
                         how='inner')
non_comm_comb = pd.merge(non_comm_comb,
                         sen_org_dis,
                         on=['Country','Year', 'Region Code', 'Region Name', 'Country Code', 'Sex', 'Age Group'],
                         how='inner')
non_comm_comb = pd.merge(non_comm_comb,
                         skin_dis,
                         on=['Country','Year', 'Region Code', 'Region Name', 'Country Code', 'Sex', 'Age Group'],
                         how='inner')
non_comm_comb = pd.merge(non_comm_comb,
                         sids,
                         on=['Country','Year', 'Region Code', 'Region Name', 'Country Code', 'Sex', 'Age Group'],
                         how='inner')

non_comm_comb.head()

# Merge non_comm_comb, df & mort_comb data sets

# Merge df and mort_comb data sets
df_comb2 = pd.merge(df, mort_comb, on = ["Country", "Year"])

# Merge df and mort_comb data sets
df_comb3 = pd.merge(df_comb2, non_comm_comb, on = ["Country", "Year"])
df_comb3

# Remove white space from all column titles in pandas dataframe
df_comb3.columns = df_comb3.columns.str.strip() 

# Lowercase all column titles in pandas dataframe
df_comb3.columns = [x.lower() for x in df_comb3.columns]

# Remove NA values
df_comb3 = df_comb3.dropna()


df_comb3.head()

# Priorities by 3/18
#1) Run a linear regression model to determine what factors are the statistically significant - Nick & Soham
# Find the statistically significant variables for life expectancy
#model_lin = sm.OLS.from_formula("life expectancy ~ blah + blah + blah +  blah + blah", data=df)
#result_lin = model_lin.fit()
#result_lin.summary()
#### Need to remove irrelevant columns 
#2) Answer the third business question - should a country with a lower life expectancy value (<65) increase its healthcare expenditures in order to improve its average life span? 
#### Look at top and bottom countries - gdp spent %
#3) Clean-up data set
#### Find potential outliers in data set (df_comb3) / run cross validation - Adrianne 
#### How do we want to handle zeroes?

# Remove the cause of death categories from df

# Merge World Bank df of % spent on schooling

# To find the correlation among the variables in data set
# the columns using pearson method
pcorr_df_comb = df_comb.corr(method ='pearson')
pcorr_df_comb

# Utilize heatmap to better identify stronger relationships
plt.figure(figsize=(16, 6))
sns.heatmap(pcorr_df_comb, vmin=-1, vmax=1, annot=True)

# Verify that non-communicable diseases are the most common cause of death within developing countries

# Create a scatterplot matricess

import seaborn as sns
sns.pairplot(df_comb, y_vars='life expectancy', x_vars=df_comb.columns.values)

# Create a correlation 

# To find the correlation among the variables in data set
# the columns using pearson method
pcorr_df_comb3 = df_comb3.corr(method ='pearson')
pcorr_df_comb3

# Utilize heatmap to better identify stronger relationships
plt.figure(figsize=(16, 6))
sns.heatmap(pcorr_df_comb3, vmin=-1, vmax=1, annot=True)

"""## **The following block of codes is for the linear regression model**
Run on df_comb and df_comb3
"""

import numpy as np
import pandas as pd

df_combln=df_comb

df_combln

# Checking for null values
print(df_combln.info())

# Checking for outliers
print(df_combln.describe())

#Making a copy of the dataframe
df_combln2=df_combln
df_combln3=df_combln

# Converting the status variable into numerical
varlist =  ['status']

# Defining the map function
def binary_map(x):
    return x.map({'Developed': 1, "Developing": 0})

# Applying the function to the dataframe list
df_combln2[varlist] = df_combln2[varlist].apply(binary_map)

# Check the dataframe now
df_combln2

#Code block for scatter plot

#df_combln2.plot.scatter(x='gdp_healthcare',y='life expectancy')

#df_combln2.plot.scatter(x='gdp_healthcare',y='life expectancy',c='status',cmap='viridis')

# Converting the status variable into numerical
varlist5 =  ['region code']

# Defining the map function
def binary_map(x):
    return x.map({'EU': 10, 'OA': 0,'NAC': 20,'CSA': 30,'AS': 40,'AF': 50})

# Applying the function to the dataframe list
df_combln2[varlist5] = df_combln2[varlist5].apply(binary_map)

# Check the dataframe now
df_combln2['region code']

#Removing certain columns

#df_combln2.pop('country')
#df_combln2.pop('country code')
#df_combln2.pop('region name')


df_combln2

# Creating dummy variable
sex_dum = pd.get_dummies(df_combln3['sex'])

# Check what the dataset 'sex_dum' looks like
sex_dum

# Dropping the fourth  column ("Unknown") from sex_dum dataset
#sex_dum = pd.get_dummies(df_combln2['sex'], drop_fourth = True)

# Adding the sex_dum to the original df_combln2 dataframe
df_combln2 = pd.concat([df_combln2, sex_dum], axis = 1)

# Dropping 'sex' as we have created the dummies for it
df_combln2.drop(['sex'], axis = 1, inplace = True)

df_combln2

# Creating dummy variable for age group
age_group_dum = pd.get_dummies(df_combln3['age group'])

# Check what the dataset 'sex_dum' looks like
age_group_dum

# Adding the age_group_dum to the original df_combln2 dataframe
df_combln2 = pd.concat([df_combln2, age_group_dum], axis = 1)

# Dropping 'age group' as we have created the dummies for it
df_combln2.drop(['age group','country','region code','region name','country code'], axis = 1, inplace = True)

df_combln2

# Converting the Columns from String/Int type to Float

# df_combln2['region code'] = pd.to_numeric(df_combln['region code'], errors='coerce')
# df_combln2['country'] = pd.to_numeric(df_combln['country'], errors='coerce')
# df_combln2['sex'] = pd.to_numeric(df_combln['sex'], errors='coerce')
# df_combln2['status'] = pd.to_numeric(df_combln['status'], errors='coerce')
# df_combln2['region name'] = pd.to_numeric(df_combln['region name'], errors='coerce')
# df_combln2['age group'] = pd.to_numeric(df_combln['age group'], errors='coerce')
# df_combln2['country code'] = pd.to_numeric(df_combln['country code'], errors='coerce')

# df_combln2['year'] = df_combln['year'].astype(float)
# df_combln2['under-five deaths'] = df_combln['under-five deaths'].astype(float)
# df_combln['infant deaths'] = df_combln['infant deaths'].astype(float)

# print(df_combln.dtypes)

#print(df_combln.dtypes)

#Replacing the NAN values with 0

##df_combln = df_combln.replace(np.nan, 0, regex=True)
df_combln

from sklearn.model_selection import train_test_split

# We specify random seed so that the train and test data set always have the same rows, respectively
# 80 :20 split
np.random.seed(0)
df_combln2_train, df_combln2_test = train_test_split(df_combln2, train_size = 0.8, test_size = 0.2, random_state = 100)

from sklearn.feature_selection import RFE
from sklearn.linear_model import LinearRegression

y_train = df_combln2_train.pop('life expectancy')
X_train = df_combln2_train

df_combln2

lm = LinearRegression()
lm.fit(X_train, y_train)

rfe = RFE(lm)
rfe = rfe.fit(X_train, y_train)

list(zip(X_train.columns,rfe.support_,rfe.ranking_))

X_train_rfe = X_train[['year','gdp_healthcare','status','adult mortality','infant deaths','bmi','under-five deaths','gdp','population','income composition of resources','schooling','inj','comm_dis','ill','non_comm','All','Female','Male','Unknown','[0]','[1-4]','[5-9]','[10-14]','[15-19]','[20-24]','[25-29]','[30-34]','[35-39]','[40-44]','[45-49]','[50-54]','[55-59]','[60-64]','[65-69]','[70-74]','[75-79]','[80-84]','[85+]','[All]','[Unknown]']]

# Adding a constant variable 
import statsmodels.api as sm  
X_train_rfe = sm.add_constant(X_train_rfe)

lm = sm.OLS(y_train,X_train_rfe).fit()   # Running the linear model

print(lm.summary())

X_train_rfe2 = X_train[['gdp_healthcare','adult mortality','income composition of resources','schooling',]]

# Adding a constant variable 
import statsmodels.api as sm  
X_train_rfe2 = sm.add_constant(X_train_rfe2)

lm9 = sm.OLS(y_train,X_train_rfe2).fit()   # Running the linear model

print(lm9.summary())

# Commented out IPython magic to ensure Python compatibility.
y_train_price = lm.predict(X_train_rfe)
# Importing the required libraries for plots.
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

# Plot the histogram of the error terms
fig = plt.figure()
sns.distplot((y_train - y_train_price), bins = 20)
fig.suptitle('Error Terms', fontsize = 20)                  # Plot heading 
plt.xlabel('Errors', fontsize = 18)                         # X-label

#Evaluating the model on test data

y_test = df_combln2_test.pop("life expectancy")
X_test = df_combln2_test

# Now let's use our model to make predictions.

# Creating X_test_new dataframe by dropping variables from X_test
# X_test_new = X_test[X_train_rfe.columns]

# Adding a constant variable 
X_test_new = sm.add_constant(X_test)

# Making predictions
y_pred = lm.predict(X_test_new)

from sklearn.metrics import r2_score
r2_score(y_true = y_test, y_pred = y_pred)

plt.scatter(X_train, y_train,color='g')
plt.plot(X_test, y_pred,color='k')

plt.show()


plt.title("Salary vs Experience (Training set)")
plt.xlabel("Years of Experience")
plt.ylabel("Salary")
plt.show()

X_train

y_train

#Making the linear regression model for the data frame df_comb3

df_comb3ln=df_comb3
df_comb3ln
print(df_comb3ln.columns)

#Checking for null values
print(df_comb3ln.info())

# Checking for outliers
print(df_comb3ln.describe())

#Int Columns to float
df_comb3ln['infant deaths'] = df_comb3ln['infant deaths'].astype(float)
df_comb3ln['under-five deaths'] = df_comb3ln['under-five deaths'].astype(float)
df_comb3ln['year'] = df_comb3ln['year'].astype(float)


#Object columns to float

df_comb3ln['country'] = pd.to_numeric(df_comb3ln['country'], errors='coerce')
df_comb3ln['status'] = pd.to_numeric(df_comb3ln['status'], errors='coerce')
df_comb3ln['region code_x'] = pd.to_numeric(df_comb3ln['region code_x'], errors='coerce')
df_comb3ln['region name_x'] = pd.to_numeric(df_comb3ln['region name_x'], errors='coerce')
df_comb3ln['age group_x'] = pd.to_numeric(df_comb3ln['age group_x'], errors='coerce')
df_comb3ln['country code_x'] = pd.to_numeric(df_comb3ln['country code_x'], errors='coerce')
df_comb3ln['sex_x'] = pd.to_numeric(df_comb3ln['sex_x'], errors='coerce')
df_comb3ln['region code_y'] = pd.to_numeric(df_comb3ln['region code_y'], errors='coerce')
df_comb3ln['region name_y'] = pd.to_numeric(df_comb3ln['region name_y'], errors='coerce')
df_comb3ln['country code_y'] = pd.to_numeric(df_comb3ln['country code_y'], errors='coerce')
df_comb3ln['sex_y'] = pd.to_numeric(df_comb3ln['sex_y'], errors='coerce')
df_comb3ln['age group_y'] = pd.to_numeric(df_comb3ln['age group_y'], errors='coerce')



print(df_comb3ln.info())

df_comb3ln = df_comb3ln.replace(np.nan, 0, regex=True)

from sklearn.model_selection import train_test_split

# We specify random seed so that the train and test data set always have the same rows, respectively
np.random.seed(0)
df_comb3ln_train, df_comb3ln_test = train_test_split(df_comb3ln, train_size = 0.8, test_size = 0.2, random_state = 100)

from sklearn.feature_selection import RFE
from sklearn.linear_model import LinearRegression

y2_train = df_comb3ln_train.pop('life expectancy')
X2_train = df_comb3ln_train

#Code Crashing hence commented

#lm2 = LinearRegression()
#lm2.fit(X2_train, y2_train)

#rfe = RFE(lm2)
#rfe = rfe.fit(X2_train, y2_train)

#list(zip(X2_train.columns,rfe.support_,rfe.ranking_))

#Making a copy of the df_comb3ln
df_comb3ln_limited=df_comb3ln

#Modifying df_comb3ln to consist of only the   diseases vs life expectancy
df_comb3ln_limited.pop('year')

df_comb3ln_limited.pop('gdp_healthcare')

df_comb3ln_limited.pop('status')

df_comb3ln_limited.pop('adult mortality')

df_comb3ln_limited.pop('infant deaths')

df_comb3ln_limited.pop('bmi')

df_comb3ln_limited.pop('under-five deaths')

df_comb3ln_limited.pop('gdp')

df_comb3ln_limited.pop('population')

df_comb3ln_limited.pop('schooling')

df_comb3ln_limited.pop('region code_x')

df_comb3ln_limited.pop('region name_x',)

df_comb3ln_limited.pop('country code_x')

df_comb3ln_limited.pop('sex_x')

df_comb3ln_limited.pop('region code_y')

df_comb3ln_limited.pop('age group_x')

df_comb3ln_limited.pop('region name_y')

df_comb3ln_limited.pop('country code_y')

df_comb3ln_limited.pop('income composition of resources')

df_comb3ln_limited.pop('age group_y')

df_comb3ln_limited.pop('sex_y')

df_comb3ln_limited.pop('country')


df_comb3ln_limited

#Making a new data frame for the life expectancy vs non communicable diseases

df_comb3ln_limited2=df_comb3ln_limited

df_comb3ln_limited2.pop('inj')

df_comb3ln_limited2.pop('comm_dis')

df_comb3ln_limited2.pop('non_comm')

df_comb3ln_limited2.pop('ill')

df_comb3ln_limited2

df_comb3ln_limited2 = df_comb3ln_limited2.replace(np.nan, 0, regex=True)

from sklearn.model_selection import train_test_split

# We specify random seed so that the train and test data set always have the same rows, respectively
np.random.seed(0)
df_comb3ln_limited2_train, df_comb3ln_limited2_test = train_test_split(df_comb3ln_limited2, train_size = 0.7, test_size = 0.3, random_state = 100)

from sklearn.feature_selection import RFE
from sklearn.linear_model import LinearRegression


y3_train = df_comb3ln_limited2_train.pop('life expectancy')
X3_train = df_comb3ln_limited2_train

lm3 = LinearRegression()
lm3.fit(X3_train, y3_train)

import statsmodels.api as sm
X3_train_lm = sm.add_constant(X3_train)

lr_1 = sm.OLS(y3_train, X3_train_lm).fit()

lr_1.summary()

X3_train_rfe = X3_train[['cardio_dis','cong_anom','dia_end','dig_dis','genit_dis','mal_neo','mus_skel_dis','neur_psy','oral_con','oth_neo','resp_dis','sen_org_dis','skin_dis','sids']]

# Adding a constant variable 
import statsmodels.api as sm  
X3_train_rfe = sm.add_constant(X3_train_rfe)

lm3 = sm.OLS(y3_train,X3_train_rfe).fit()   # Running the linear model

print(lm3.summary())

# Commented out IPython magic to ensure Python compatibility.
y3_train_price = lm3.predict(X3_train_rfe)
# Importing the required libraries for plots.
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

# Plot the histogram of the error terms
fig = plt.figure()
sns.distplot((y3_train - y3_train_price), bins = 20)
fig.suptitle('Error Terms', fontsize = 20)                  # Plot heading 
plt.xlabel('Errors', fontsize = 18)                         # X-label

plt.scatter(X_train, y_train,color='g') 
plt.plot(X_test, y_pred,color='k') 

plt.show()


plt.title("Salary vs Experience (Training set)")
plt.xlabel("Years of Experience")
plt.ylabel("Salary")
plt.show()

#from sklearn.linear_model import LinearRegression #linear regression model

#import numpy as np 

#import pandas as pd 

#from matplotlib import pyplot as plt 

#import seaborn as sns 
#from sklearn import linear_model

#Creating a new dataframe
#df_combln=df_comb
#df_combln
#Independent variables


#X = df_combln[['country','year', 'gdp_healthcare','status', 'adult mortality','infant deaths','bmi', 'under-five deaths' ,'gdp' ,'schooling' ,'region code' ,'region name','country code', 'sex', 'age group' ,'inj', 'comm_dis', 'ill','non_comm']]
#X1 = df_combln[['year', 'gdp_healthcare', 'adult mortality','infant deaths','bmi', 'under-five deaths' ,'gdp' ,'schooling'  ,'inj', 'comm_dis', 'ill','non_comm']]

#Dependent Variables
#y = df_combln['life expectancy']


#age_group
# Convert DataFrame column from string to float
#df_combln['country'] = df_combln['country'].astype(float)
#df_combln['status'] = df_combln['status'].astype(float)
#df_combln['region code'] = df_combln['region code'].astype(float)
#df_combln['region name'] = df_combln['region name'].astype(float)
#df_combln['country code'] = df_combln['country code'].astype(float)
#df_combln['sex'] = df_combln['sex'].astype(float)



#regr = linear_model.LinearRegression()
#model=regr.fit(X1, y)

#Y_pred = model.predict(X1)
#response = model.predict(X1)

#r2 = model.score(X1, y)

#plt.scatter(X1, y)
#plt.plot(X, Y_pred, color='red')
#plt.show()

#model_lin = plt.plot('life expectancy ~ country + year + gdp_healthcare + status+ adult mortality + infant deaths + bmi + under-five deaths + gdp + schooling + region code + region name + country code + sex + age group + inj + comm_dis+ ill + non_comm', data=df_comb)
#result_lin = model_lin.fit()
#result_lin.summary()

"""### **The following block of codes is for the KNN Classification Model**"""

# Create a new dataframe with applicable variables
# Look at the available columns
df_comb.info()

# Create a new dataframe 
df_combknn = df_comb[['gdp_healthcare', 'adult mortality', 'schooling', 'life expectancy']] 
# Show new dataframe
df_combknn

#Import libraries for knn model

from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

# Create x and y data sets

x_data = df_combknn.drop(['life expectancy'],axis=1) #X variables just exclude life expectancy
y_data = df_combknn['life expectancy'] #y variable is life expectancy

print(x_data)

print(y_data)

# Cannot have continuous variable for knn classification model - convert y variable to categorical values

# Import libraries 
from sklearn import preprocessing
from sklearn import utils

# Convert y values to categorical values
proc_lab = preprocessing.LabelEncoder()
y_data_new = proc_lab.fit_transform(y_data)

# Print new converted y values
print(y_data_new)

# Split life expectancy data set into test and training data sets (80/20 split)
X_train, X_test, y_train, y_test = train_test_split(df_combknn, y_data_new,test_size=0.2, random_state = 1)

knn_model=KNeighborsClassifier() #create variable for knn classifier
knn_model.fit(X_train,y_train) #apply classifier to training data set
ypred=knn_model.predict(X_test) #predict life expectancy using test data set

# Visualize classification model results

# Create confusion matrix
conf_matrix = confusion_matrix(y_test, ypred)
print('Confusion Matrix:')
print(conf_matrix)

# Display the max height of code results
from IPython.display import Javascript
display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 5000})'''))

# Create classification report
knn_class = classification_report(y_test, ypred)
print('KNN Classification Report:')
print(knn_class)

# Display the max height of code results
from IPython.display import Javascript
display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 5000})'''))

# Show accuracy score for KNN Model
accuracy_score = accuracy_score(y_test,ypred)
print('The accuracy score of the KNN classification model is:', accuracy_score)

"""### **The following block of codes is for the neural network model (MLPRegressor)**"""

# Import required libraries

import pandas as pd

import numpy as np 

import matplotlib.pyplot as plt

import sklearn

from sklearn.neural_network import MLPClassifier

from sklearn.neural_network import MLPRegressor

from sklearn.metrics import classification_report,confusion_matrix


# Import necessary modules

from sklearn.model_selection import train_test_split

from sklearn.metrics import mean_squared_error

from math import sqrt

from sklearn.metrics import r2_score

# Create a new dataframe with applicable variables
# Look at the available columns
df.info()

# Create a new dataframe 
df_combnn = df[['GDP_Healthcare', 'Adult Mortality', 'Schooling', 'Income composition of resources','Life expectancy ']] 

# Drop duplicating rows of data
df_combnn.drop_duplicates()

# Drop all N/A rows 
df_combnn2 = df_combnn.dropna()

# Show new dataframe
df_combnn2

# Create x and y data sets

x_data = df_combnn2.drop(['Life expectancy '],axis=1) #X variables just exclude life expectancy
y_data = df_combnn2['Life expectancy '] #y variable is life expectancy

# Split life expectancy data set into test and training data sets (70/30 split)
X_train, X_test, y_train, y_test = train_test_split(df_combnn2, y_data,test_size=0.3, random_state = 1)

x_data

# Create variable for MLP Regressor
mlp = MLPRegressor(hidden_layer_sizes=(100, 50,25), activation='relu', alpha=0.0001, random_state=20)

# Fit the training data set into the MLP Classifier
mlp.fit(X_train,y_train)

# Predict using the training data set 
pred_train = mlp.predict(X_train)

# Predict using the test data set
pred_test = mlp.predict(X_test)

import numpy as np
from sklearn.metrics import mean_squared_error

# Calculate accuracy and error metrics
test_r2 = mlp.score(X_test, y_test)
test_rmse = np.sqrt(mean_squared_error(y_test, pred_test))

# Print R_squared and RMSE value
print('R_squared value: ', test_r2)
print('RMSE: ', test_rmse)

# Create a dataframe of test actual vs prediction 
df_nnresults = pd.DataFrame({'Actual': y_test, 'Predicted': pred_test})
df_nnresults.head()

# Create a dataframe of training actual vs prediction 
df_nnresults2 = pd.DataFrame({'Actual': y_train, 'Predicted': pred_train})
df_nnresults2.head()

# Plot the regressor model
df_nnresults.plot.scatter(x='Actual',y='Predicted', c='Predicted', colormap='viridis')

# Plot regressor model based on training data
train_plot = sns.regplot(x = 'Actual',
            y = 'Predicted',
            data = df_nnresults2)
sns.set(rc={"figure.figsize":(15, 15)})



# Plot regressor model based on testing data
sns.regplot(x = 'Actual',
            y = 'Predicted',
            data = df_nnresults)

# Show number of inputs, outputs, layers, and sizes for coefficients in the hidden layers:

print(f"Number of inputs:  {mlp.n_features_in_}")
print(f"Number of outputs: {mlp.n_outputs_}")
print(f"Number of layers:  {mlp.n_layers_}")
print(f"Layer sizes: {[l.shape for l in mlp.coefs_]}")
print("Number of Iterations for Which Estimator Ran : ", mlp.n_iter_)
print("Number of Intercepts : ", len(mlp.intercepts_))
print("Loss: ",mlp.loss_)

"""### **The following block of codes is for the Random Forest model (attempt)**"""

from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.model_selection import cross_val_score

RF = RandomForestRegressor(n_estimators = 100, random_state = 10)
RF.fit(X_train, y_train)

y_pred = RF.predict(X_test)
np.set_printoptions(precision = 2)
y_pred = np.array(y_pred)
y_test = np.array(y_test)

print(np.concatenate((y_pred.reshape(len(y_test), 1), y_test.reshape(len(y_test), 1)), 1))

# Accuracy Score
accuracy_score = RF.score(X_test, y_test)
print('Random Forest Classifier Accuracy:', (accuracy_score)*100, '%')

# Mean Squared Error
print('Random Forest Mean Squared Error:', mean_squared_error(y_test, y_pred)**(0.5))

# Cross-Validation
accuracies = cross_val_score(RF, X_train, y_train, cv = 10)
accuracies.mean()